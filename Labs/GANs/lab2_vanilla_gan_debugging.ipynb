{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IB5WAhv0N3T5"
      },
      "source": [
        "# Lab 2: Debug a Broken Vanilla GAN (find 12+ issues)"
      ],
      "id": "IB5WAhv0N3T5"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchvision, torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "IMAGE_SIZE = 28\n"
      ],
      "metadata": {
        "id": "87X7q_-qOnuq"
      },
      "id": "87X7q_-qOnuq",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   **Normalization:** Add an extra transformation for normalizing the data because we are using\n",
        "  tanh as an activation function (range -1, 1)\n",
        "2.   **Image resizing:** Standarize all images size to 28x28\n",
        "3. **Missing activation:** Adding a tanh activation in the generator\n",
        "4. **Z reshape**: the generator takes input z 1x100, so we need to reshape the input to 100 instead of 64\n",
        "5. **Double use of sigmoid:** We are using BCE with logits as our loss function, which internally use sigmoid. Therefore, we can remove the last sigmoid layer in the discriminator\n",
        "6. **-1 in view():**:    \"return self.net(x).view(x.size(0), -1)\"\n",
        "7. TODO: FIX TRAINING LOGIC\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5XW9JzdqO8U5"
      },
      "id": "5XW9JzdqO8U5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGt48FfKN3T6",
        "outputId": "ff40b1e3-f8b1-4902-8eb3-66d52ffec279"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 18.7MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 509kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.66MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.24MB/s]\n"
          ]
        }
      ],
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "transform=transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5), (0.5)), # (input - mean) / std. (Single channel)\n",
        "\n",
        "    ])\n",
        "loader=DataLoader(torchvision.datasets.MNIST('./data',True,download=True,transform=transform),batch_size=256,shuffle=True)"
      ],
      "id": "VGt48FfKN3T6"
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(loader))\n",
        "print('Image shape:', images.shape)\n",
        "print('Label shape:', labels.shape)\n",
        "print('First label:', labels[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kHHhkDUcfl1",
        "outputId": "2038bebc-984a-421c-8d73-463300145511"
      },
      "id": "6kHHhkDUcfl1",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: torch.Size([256, 1, 28, 28])\n",
            "Label shape: torch.Size([256])\n",
            "First label: tensor(3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z_dim = 100\n",
        "g_lr = 2e-2\n",
        "d_lr = 2e-5\n",
        "\n",
        "class D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 4, 2, 1),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            nn.Conv2d(32, 64, 4, 2, 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            nn.Conv2d(64, 1, 7, 1, 0)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x).view(x.size(0), -1)\n",
        "\n",
        "class G(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.ConvTranspose2d(100, 128, 4, 1, 0),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(64, 1, 4, 2, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        z = z.view(z.size(0), 100, 1, 1)\n",
        "        return self.net(z)\n",
        "\n",
        "Dnet = D().to(device)\n",
        "Gnet = G().to(device)\n",
        "\n",
        "crit = nn.BCEWithLogitsLoss()\n",
        "opt_d = torch.optim.Adam(Dnet.parameters(), lr=d_lr, betas=(0.9, 0.999))\n",
        "opt_g = torch.optim.Adam(Gnet.parameters(), lr=g_lr, betas=(0.9, 0.999))"
      ],
      "metadata": {
        "id": "4aftqBJpWHEL"
      },
      "id": "4aftqBJpWHEL",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJQCL7rHN3T7"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "for real,_ in tqdm(loader):\n",
        "    real=real.to(device); b=real.size(0)\n",
        "    z=torch.randn(b,z_dim,device=device); fake=Gnet(z.view(b,z_dim,1,1))\n",
        "    loss_d=crit(Dnet(real),torch.zeros(b,1,device=device))+crit(Dnet(fake),torch.ones(b,1,device=device))  # BUG labels\n",
        "    loss_d.backward(); opt_g.step()  # BUG\n",
        "    z=torch.randn(b,z_dim,device=device); fake=Gnet(z.view(b,z_dim,1,1))\n",
        "    loss_g=crit(Dnet(fake),torch.zeros(b,1,device=device))  # BUG non-sat\n",
        "    loss_g.backward()  # BUG missing step\n",
        "print('Now fix all the issues.')"
      ],
      "id": "DJQCL7rHN3T7"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}